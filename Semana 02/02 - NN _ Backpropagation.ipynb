{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ivCcAyJxSj"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "\n",
        "# Lista 2 - NN & Backpropagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "_________________________________________\n",
        "\n",
        "Antes de começar o exercício,  não se esqueça de instalar todos os pacotes necessários para a sua execução.  "
      ],
      "metadata": {
        "id": "5EbG7paYJ-sT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hF9mL2iuJxSl",
        "outputId": "ba324649-54f3-4a81-fb60-c2ada49b6a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U58nHrAJxSn"
      },
      "source": [
        "## Perceptron\n",
        "\n",
        "O perceptron é uma \"rede neural\" de um só neurônio.  No nosso caso, temos a rede mais simples possível, com uma só entrada e uma só saída, sem ativação.\n",
        "\n",
        "Temos 100 dados que serão usados para treinar 300 épocas do percéptron.\n",
        "\n",
        "Vamos utilizar o modelo percéptron para aprender uma simples regressão linear, o objetivo é faze-lo aprender uma simples equação linear e tambem se acostumar com a sintaxe e funcionamento do TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "YElbceStJxSn"
      },
      "outputs": [],
      "source": [
        "def f1(x):\n",
        "    '''\n",
        "    Funcao a ser aprendida\n",
        "    '''\n",
        "    return 5 + 10*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "JDqMORncJxSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bf33b9-6551-41bc-ad07-e39b9acfad06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 xs= [ 0.          0.1010101   0.2020202   0.3030303   0.4040404   0.50505051\n",
            "  0.60606061  0.70707071  0.80808081  0.90909091  1.01010101  1.11111111\n",
            "  1.21212121  1.31313131  1.41414141  1.51515152  1.61616162  1.71717172\n",
            "  1.81818182  1.91919192  2.02020202  2.12121212  2.22222222  2.32323232\n",
            "  2.42424242  2.52525253  2.62626263  2.72727273  2.82828283  2.92929293\n",
            "  3.03030303  3.13131313  3.23232323  3.33333333  3.43434343  3.53535354\n",
            "  3.63636364  3.73737374  3.83838384  3.93939394  4.04040404  4.14141414\n",
            "  4.24242424  4.34343434  4.44444444  4.54545455  4.64646465  4.74747475\n",
            "  4.84848485  4.94949495  5.05050505  5.15151515  5.25252525  5.35353535\n",
            "  5.45454545  5.55555556  5.65656566  5.75757576  5.85858586  5.95959596\n",
            "  6.06060606  6.16161616  6.26262626  6.36363636  6.46464646  6.56565657\n",
            "  6.66666667  6.76767677  6.86868687  6.96969697  7.07070707  7.17171717\n",
            "  7.27272727  7.37373737  7.47474747  7.57575758  7.67676768  7.77777778\n",
            "  7.87878788  7.97979798  8.08080808  8.18181818  8.28282828  8.38383838\n",
            "  8.48484848  8.58585859  8.68686869  8.78787879  8.88888889  8.98989899\n",
            "  9.09090909  9.19191919  9.29292929  9.39393939  9.49494949  9.5959596\n",
            "  9.6969697   9.7979798   9.8989899  10.        ]\n",
            "100 ys= [  5.           6.01010101   7.02020202   8.03030303   9.04040404\n",
            "  10.05050505  11.06060606  12.07070707  13.08080808  14.09090909\n",
            "  15.1010101   16.11111111  17.12121212  18.13131313  19.14141414\n",
            "  20.15151515  21.16161616  22.17171717  23.18181818  24.19191919\n",
            "  25.2020202   26.21212121  27.22222222  28.23232323  29.24242424\n",
            "  30.25252525  31.26262626  32.27272727  33.28282828  34.29292929\n",
            "  35.3030303   36.31313131  37.32323232  38.33333333  39.34343434\n",
            "  40.35353535  41.36363636  42.37373737  43.38383838  44.39393939\n",
            "  45.4040404   46.41414141  47.42424242  48.43434343  49.44444444\n",
            "  50.45454545  51.46464646  52.47474747  53.48484848  54.49494949\n",
            "  55.50505051  56.51515152  57.52525253  58.53535354  59.54545455\n",
            "  60.55555556  61.56565657  62.57575758  63.58585859  64.5959596\n",
            "  65.60606061  66.61616162  67.62626263  68.63636364  69.64646465\n",
            "  70.65656566  71.66666667  72.67676768  73.68686869  74.6969697\n",
            "  75.70707071  76.71717172  77.72727273  78.73737374  79.74747475\n",
            "  80.75757576  81.76767677  82.77777778  83.78787879  84.7979798\n",
            "  85.80808081  86.81818182  87.82828283  88.83838384  89.84848485\n",
            "  90.85858586  91.86868687  92.87878788  93.88888889  94.8989899\n",
            "  95.90909091  96.91919192  97.92929293  98.93939394  99.94949495\n",
            " 100.95959596 101.96969697 102.97979798 103.98989899 105.        ]\n"
          ]
        }
      ],
      "source": [
        "xs = np.linspace(0,10,100)  # gera 100 valores no intervalo [0.10]\n",
        "ys = f1(xs)                 # computa o valor de f1 nestes 100 valores\n",
        "print(len(xs), \"xs=\", xs)\n",
        "print(len(ys), \"ys=\", ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "scrolled": true,
        "id": "0FPmfqsRJxSp",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcebee63-d663-454a-ee5c-a36b353edf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1306.9207  \n",
            "Epoch 2/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1857 \n",
            "Epoch 3/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3235 \n",
            "Epoch 4/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1520 \n",
            "Epoch 5/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8956 \n",
            "Epoch 6/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7152 \n",
            "Epoch 7/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6092 \n",
            "Epoch 8/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4896 \n",
            "Epoch 9/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5812 \n",
            "Epoch 10/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3710 \n",
            "Epoch 11/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4720 \n",
            "Epoch 12/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3099 \n",
            "Epoch 13/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0940 \n",
            "Epoch 14/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1358 \n",
            "Epoch 15/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1858 \n",
            "Epoch 16/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8473 \n",
            "Epoch 17/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6291 \n",
            "Epoch 18/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8045 \n",
            "Epoch 19/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5221 \n",
            "Epoch 20/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6670 \n",
            "Epoch 21/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5937 \n",
            "Epoch 22/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4213 \n",
            "Epoch 23/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3423 \n",
            "Epoch 24/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4336 \n",
            "Epoch 25/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2805 \n",
            "Epoch 26/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2842 \n",
            "Epoch 27/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2091 \n",
            "Epoch 28/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0967 \n",
            "Epoch 29/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0736 \n",
            "Epoch 30/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0687 \n",
            "Epoch 31/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0614 \n",
            "Epoch 32/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0713 \n",
            "Epoch 33/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9841 \n",
            "Epoch 34/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9581 \n",
            "Epoch 35/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9660 \n",
            "Epoch 36/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8684 \n",
            "Epoch 37/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8927 \n",
            "Epoch 38/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7494 \n",
            "Epoch 39/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8799 \n",
            "Epoch 40/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7332 \n",
            "Epoch 41/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7368 \n",
            "Epoch 42/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6939 \n",
            "Epoch 43/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6921 \n",
            "Epoch 44/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6696 \n",
            "Epoch 45/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5805 \n",
            "Epoch 46/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6254 \n",
            "Epoch 47/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5452 \n",
            "Epoch 48/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4863 \n",
            "Epoch 49/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5121 \n",
            "Epoch 50/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5170 \n",
            "Epoch 51/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4739 \n",
            "Epoch 52/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4599 \n",
            "Epoch 53/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4105 \n",
            "Epoch 54/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4533 \n",
            "Epoch 55/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4297 \n",
            "Epoch 56/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3787 \n",
            "Epoch 57/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3366 \n",
            "Epoch 58/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3301 \n",
            "Epoch 59/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3486 \n",
            "Epoch 60/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3278 \n",
            "Epoch 61/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3022 \n",
            "Epoch 62/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3037 \n",
            "Epoch 63/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2775 \n",
            "Epoch 64/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2813 \n",
            "Epoch 65/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2720 \n",
            "Epoch 66/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2531 \n",
            "Epoch 67/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2428 \n",
            "Epoch 68/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2289 \n",
            "Epoch 69/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2114 \n",
            "Epoch 70/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2339 \n",
            "Epoch 71/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2084 \n",
            "Epoch 72/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2096 \n",
            "Epoch 73/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1872 \n",
            "Epoch 74/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2031 \n",
            "Epoch 75/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2043 \n",
            "Epoch 76/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1854 \n",
            "Epoch 77/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1759 \n",
            "Epoch 78/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1655 \n",
            "Epoch 79/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1622 \n",
            "Epoch 80/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1549 \n",
            "Epoch 81/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1516 \n",
            "Epoch 82/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1336 \n",
            "Epoch 83/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1347 \n",
            "Epoch 84/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1282 \n",
            "Epoch 85/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1206 \n",
            "Epoch 86/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1326\n",
            "Epoch 87/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1162\n",
            "Epoch 88/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1097 \n",
            "Epoch 89/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1062 \n",
            "Epoch 90/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0967 \n",
            "Epoch 91/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1106\n",
            "Epoch 92/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0914 \n",
            "Epoch 93/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0946 \n",
            "Epoch 94/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0822 \n",
            "Epoch 95/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0815 \n",
            "Epoch 96/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0783\n",
            "Epoch 97/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0807 \n",
            "Epoch 98/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0762 \n",
            "Epoch 99/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0761  \n",
            "Epoch 100/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0640 \n",
            "Epoch 101/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0685 \n",
            "Epoch 102/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0603 \n",
            "Epoch 103/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0608 \n",
            "Epoch 104/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0609 \n",
            "Epoch 105/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0569 \n",
            "Epoch 106/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0534 \n",
            "Epoch 107/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0483 \n",
            "Epoch 108/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0471 \n",
            "Epoch 109/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0476 \n",
            "Epoch 110/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0445 \n",
            "Epoch 111/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0431 \n",
            "Epoch 112/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0461 \n",
            "Epoch 113/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0369 \n",
            "Epoch 114/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0385 \n",
            "Epoch 115/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0353 \n",
            "Epoch 116/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0370 \n",
            "Epoch 117/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0313 \n",
            "Epoch 118/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0311 \n",
            "Epoch 119/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0331 \n",
            "Epoch 120/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0320 \n",
            "Epoch 121/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0295 \n",
            "Epoch 122/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0301 \n",
            "Epoch 123/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0255 \n",
            "Epoch 124/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0251 \n",
            "Epoch 125/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0250 \n",
            "Epoch 126/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0256 \n",
            "Epoch 127/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 \n",
            "Epoch 128/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0212 \n",
            "Epoch 129/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 \n",
            "Epoch 130/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 \n",
            "Epoch 131/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 \n",
            "Epoch 132/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0186 \n",
            "Epoch 133/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0182 \n",
            "Epoch 134/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 \n",
            "Epoch 135/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0249 \n",
            "Epoch 136/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 \n",
            "Epoch 137/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 \n",
            "Epoch 138/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 \n",
            "Epoch 139/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 \n",
            "Epoch 140/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 \n",
            "Epoch 141/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 \n",
            "Epoch 142/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 \n",
            "Epoch 143/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0121 \n",
            "Epoch 144/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 \n",
            "Epoch 145/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 \n",
            "Epoch 146/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 \n",
            "Epoch 147/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 \n",
            "Epoch 148/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 \n",
            "Epoch 149/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 \n",
            "Epoch 150/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 \n",
            "Epoch 151/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 \n",
            "Epoch 152/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081\n",
            "Epoch 153/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 \n",
            "Epoch 154/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0083 \n",
            "Epoch 155/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0073 \n",
            "Epoch 156/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 \n",
            "Epoch 157/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 \n",
            "Epoch 158/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 \n",
            "Epoch 159/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 \n",
            "Epoch 160/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 \n",
            "Epoch 161/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 \n",
            "Epoch 162/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 \n",
            "Epoch 163/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 \n",
            "Epoch 164/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 \n",
            "Epoch 165/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 \n",
            "Epoch 166/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 \n",
            "Epoch 167/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 \n",
            "Epoch 168/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045 \n",
            "Epoch 169/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 \n",
            "Epoch 170/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 \n",
            "Epoch 171/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 \n",
            "Epoch 172/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 \n",
            "Epoch 173/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 \n",
            "Epoch 174/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 \n",
            "Epoch 175/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 \n",
            "Epoch 176/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 \n",
            "Epoch 177/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 \n",
            "Epoch 178/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 \n",
            "Epoch 179/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 \n",
            "Epoch 180/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 \n",
            "Epoch 181/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 \n",
            "Epoch 182/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 \n",
            "Epoch 183/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 \n",
            "Epoch 184/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 \n",
            "Epoch 185/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 \n",
            "Epoch 186/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 \n",
            "Epoch 187/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 \n",
            "Epoch 188/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 \n",
            "Epoch 189/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 \n",
            "Epoch 190/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 \n",
            "Epoch 191/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 \n",
            "Epoch 192/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 \n",
            "Epoch 193/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 \n",
            "Epoch 194/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 \n",
            "Epoch 195/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 \n",
            "Epoch 196/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 197/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 \n",
            "Epoch 198/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 \n",
            "Epoch 199/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 \n",
            "Epoch 200/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 \n",
            "Epoch 201/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 \n",
            "Epoch 202/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7999e-04 \n",
            "Epoch 203/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 \n",
            "Epoch 204/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010\n",
            "Epoch 205/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7738e-04\n",
            "Epoch 206/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.2351e-04\n",
            "Epoch 207/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8987e-04  \n",
            "Epoch 208/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3299e-04\n",
            "Epoch 209/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7694e-04 \n",
            "Epoch 210/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9238e-04 \n",
            "Epoch 211/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6048e-04 \n",
            "Epoch 212/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0193e-04 \n",
            "Epoch 213/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8918e-04 \n",
            "Epoch 214/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5032e-04 \n",
            "Epoch 215/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0078e-04 \n",
            "Epoch 216/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3738e-04 \n",
            "Epoch 217/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2845e-04 \n",
            "Epoch 218/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6716e-04 \n",
            "Epoch 219/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1484e-04 \n",
            "Epoch 220/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9228e-04 \n",
            "Epoch 221/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5652e-04 \n",
            "Epoch 222/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7356e-04 \n",
            "Epoch 223/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0782e-04\n",
            "Epoch 224/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0727e-04  \n",
            "Epoch 225/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3315e-04 \n",
            "Epoch 226/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2163e-04 \n",
            "Epoch 227/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1910e-04 \n",
            "Epoch 228/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1444e-04 \n",
            "Epoch 229/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7913e-04 \n",
            "Epoch 230/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4162e-04 \n",
            "Epoch 231/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5930e-04 \n",
            "Epoch 232/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.4047e-04\n",
            "Epoch 233/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0760e-04 \n",
            "Epoch 234/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1471e-04 \n",
            "Epoch 235/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0218e-04 \n",
            "Epoch 236/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9820e-04 \n",
            "Epoch 237/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7931e-04 \n",
            "Epoch 238/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5954e-04 \n",
            "Epoch 239/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5573e-04 \n",
            "Epoch 240/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8919e-04 \n",
            "Epoch 241/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4560e-04\n",
            "Epoch 242/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3910e-04 \n",
            "Epoch 243/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1154e-04 \n",
            "Epoch 244/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1606e-04 \n",
            "Epoch 245/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9350e-04 \n",
            "Epoch 246/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8678e-04 \n",
            "Epoch 247/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7856e-04 \n",
            "Epoch 248/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9397e-04 \n",
            "Epoch 249/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6317e-04 \n",
            "Epoch 250/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5906e-04 \n",
            "Epoch 251/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5045e-04 \n",
            "Epoch 252/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6947e-04 \n",
            "Epoch 253/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5084e-04 \n",
            "Epoch 254/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4180e-04 \n",
            "Epoch 255/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2390e-04 \n",
            "Epoch 256/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2328e-04 \n",
            "Epoch 257/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6545e-04 \n",
            "Epoch 258/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2550e-04 \n",
            "Epoch 259/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0630e-04 \n",
            "Epoch 260/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1069e-04 \n",
            "Epoch 261/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8799e-05 \n",
            "Epoch 262/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9414e-05 \n",
            "Epoch 263/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6319e-05 \n",
            "Epoch 264/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8650e-05 \n",
            "Epoch 265/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9044e-05 \n",
            "Epoch 266/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0201e-05 \n",
            "Epoch 267/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2748e-05 \n",
            "Epoch 268/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7397e-05 \n",
            "Epoch 269/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1274e-05 \n",
            "Epoch 270/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9049e-05 \n",
            "Epoch 271/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3061e-05\n",
            "Epoch 272/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.1754e-05\n",
            "Epoch 273/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.8063e-05\n",
            "Epoch 274/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.7495e-05 \n",
            "Epoch 275/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.3510e-05\n",
            "Epoch 276/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.6365e-05 \n",
            "Epoch 277/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4989e-05\n",
            "Epoch 278/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.3476e-05\n",
            "Epoch 279/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4720e-05\n",
            "Epoch 280/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.9949e-05\n",
            "Epoch 281/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0217e-05 \n",
            "Epoch 282/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7937e-05 \n",
            "Epoch 283/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.8566e-05\n",
            "Epoch 284/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8430e-05 \n",
            "Epoch 285/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.2011e-05\n",
            "Epoch 286/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4561e-05 \n",
            "Epoch 287/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.6977e-05\n",
            "Epoch 288/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.6603e-05 \n",
            "Epoch 289/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5278e-05\n",
            "Epoch 290/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.2431e-05\n",
            "Epoch 291/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1806e-05\n",
            "Epoch 292/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9936e-05 \n",
            "Epoch 293/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7933e-05 \n",
            "Epoch 294/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8786e-05\n",
            "Epoch 295/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8405e-05  \n",
            "Epoch 296/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7485e-05 \n",
            "Epoch 297/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3563e-05 \n",
            "Epoch 298/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3297e-05 \n",
            "Epoch 299/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2109e-05 \n",
            "Epoch 300/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1530e-05 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a13f0f2e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "#Definindo, compilando e treinando nosso modelo\n",
        "model = tf.keras.Sequential([\n",
        "    keras.Input(shape=(1,)),\n",
        "    keras.layers.Dense(units=1),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
        "model.fit(xs,ys,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "zdsiTFO0JxSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "0ba9548d-f66f-4ac6-8672-8f045498dadf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4\u001b[0m (20.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (20.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "v5cRyAL1JxSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395699b3-eef4-438b-d40c-6c04b4313e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a13f0f5c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "prediction: [[175.01698]]      real value: 175\n"
          ]
        }
      ],
      "source": [
        "print(\"prediction: \"+ str(model.predict(np.array([17])))+\"      real value: \" + str(f1(17)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "bvxWgdGoJxSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57aa54a-623a-467f-8888-f239f9b3ca6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5951e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.236695036117453e-05"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "val = np.linspace(0,10,63)\n",
        "model.evaluate(x=val, y=f1(val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_extrapolado = np.linspace(-10, 20, 100)\n",
        "y_val_extrapolado = f1(x_val_extrapolado)\n",
        "model.evaluate(x=x_val_extrapolado,y=y_val_extrapolado)"
      ],
      "metadata": {
        "id": "ed0fCndZtOJ5",
        "outputId": "dfeaa32a-7ce6-4cdd-c20c-b79f5b780e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0467e-04 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001824299688450992"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf9tyPeOJxSs"
      },
      "source": [
        "A função `evaluate` retorna o \"custo\" (loss) da avaliação, definido na compilação.  Nesse caso, o valor reportado é o erro quadrático médio (MSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdAtRyNiJxSt"
      },
      "source": [
        "## Aprendendo uma função não linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nOyILHhPJxSt"
      },
      "outputs": [],
      "source": [
        "def f2(x):\n",
        "    '''\n",
        "    Funcao não linear a ser aprendida\n",
        "    '''\n",
        "    return (x**2+ x**3)/200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "FUarry8nJxSu"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0,10,100)\n",
        "y = f2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rojy4bDBJxSu"
      },
      "source": [
        "# <font color='blue'>Questão 1 </font>\n",
        "Defina as camadas para esta rede neural e treine seu modelo, note que a saída unitária _não deve_ ter função de ativação (por que?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "11Obr2tKJxSv",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1bed28-950a-4dff-aa55-14e70ed31e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.0117 \n",
            "Epoch 2/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3013 \n",
            "Epoch 3/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.0609 \n",
            "Epoch 4/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.2608\n",
            "Epoch 5/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.4172 \n",
            "Epoch 6/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0240 \n",
            "Epoch 7/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.3705 \n",
            "Epoch 8/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9698 \n",
            "Epoch 9/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7921\n",
            "Epoch 10/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7017 \n",
            "Epoch 11/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6299  \n",
            "Epoch 12/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7346 \n",
            "Epoch 13/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6171 \n",
            "Epoch 14/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6993 \n",
            "Epoch 15/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4586 \n",
            "Epoch 16/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2644 \n",
            "Epoch 17/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1732 \n",
            "Epoch 18/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0688 \n",
            "Epoch 19/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5831 \n",
            "Epoch 20/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6022 \n",
            "Epoch 21/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1452 \n",
            "Epoch 22/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3204 \n",
            "Epoch 23/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5787 \n",
            "Epoch 24/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1268 \n",
            "Epoch 25/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3560\n",
            "Epoch 26/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2591 \n",
            "Epoch 27/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9745 \n",
            "Epoch 28/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9708 \n",
            "Epoch 29/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0532 \n",
            "Epoch 30/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6714 \n",
            "Epoch 31/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7960 \n",
            "Epoch 32/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6652 \n",
            "Epoch 33/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7115 \n",
            "Epoch 34/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6560 \n",
            "Epoch 35/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7361 \n",
            "Epoch 36/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3657 \n",
            "Epoch 37/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4498 \n",
            "Epoch 38/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4933 \n",
            "Epoch 39/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4835 \n",
            "Epoch 40/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2974 \n",
            "Epoch 41/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3036 \n",
            "Epoch 42/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2782 \n",
            "Epoch 43/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5101 \n",
            "Epoch 44/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2727\n",
            "Epoch 45/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1449 \n",
            "Epoch 46/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3029 \n",
            "Epoch 47/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4290 \n",
            "Epoch 48/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2336 \n",
            "Epoch 49/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1578 \n",
            "Epoch 50/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2046 \n",
            "Epoch 51/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1380 \n",
            "Epoch 52/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1264 \n",
            "Epoch 53/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2592 \n",
            "Epoch 54/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2206 \n",
            "Epoch 55/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0967 \n",
            "Epoch 56/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1528 \n",
            "Epoch 57/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2583 \n",
            "Epoch 58/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9518 \n",
            "Epoch 59/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1640 \n",
            "Epoch 60/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9892 \n",
            "Epoch 61/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0031 \n",
            "Epoch 62/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1975 \n",
            "Epoch 63/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0887\n",
            "Epoch 64/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0425 \n",
            "Epoch 65/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2012 \n",
            "Epoch 66/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9798 \n",
            "Epoch 67/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0759 \n",
            "Epoch 68/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0285 \n",
            "Epoch 69/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0150 \n",
            "Epoch 70/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9332 \n",
            "Epoch 71/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0209 \n",
            "Epoch 72/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0004 \n",
            "Epoch 73/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0697 \n",
            "Epoch 74/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0104 \n",
            "Epoch 75/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0147 \n",
            "Epoch 76/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9451 \n",
            "Epoch 77/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9539 \n",
            "Epoch 78/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9677 \n",
            "Epoch 79/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9530 \n",
            "Epoch 80/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9013 \n",
            "Epoch 81/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8445 \n",
            "Epoch 82/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9513 \n",
            "Epoch 83/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9594 \n",
            "Epoch 84/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7533 \n",
            "Epoch 85/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9299 \n",
            "Epoch 86/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7993 \n",
            "Epoch 87/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9308 \n",
            "Epoch 88/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7870 \n",
            "Epoch 89/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9129 \n",
            "Epoch 90/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9080 \n",
            "Epoch 91/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8095 \n",
            "Epoch 92/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7781 \n",
            "Epoch 93/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7901 \n",
            "Epoch 94/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9392 \n",
            "Epoch 95/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8763 \n",
            "Epoch 96/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7380 \n",
            "Epoch 97/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7042 \n",
            "Epoch 98/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8865 \n",
            "Epoch 99/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7368 \n",
            "Epoch 100/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8081 \n",
            "Epoch 101/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6995 \n",
            "Epoch 102/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6184 \n",
            "Epoch 103/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7187 \n",
            "Epoch 104/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7918 \n",
            "Epoch 105/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7680 \n",
            "Epoch 106/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6518 \n",
            "Epoch 107/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6986 \n",
            "Epoch 108/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7379 \n",
            "Epoch 109/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7236 \n",
            "Epoch 110/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7127 \n",
            "Epoch 111/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6945 \n",
            "Epoch 112/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6618 \n",
            "Epoch 113/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6265 \n",
            "Epoch 114/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6940 \n",
            "Epoch 115/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6391 \n",
            "Epoch 116/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6442 \n",
            "Epoch 117/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6532 \n",
            "Epoch 118/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6799 \n",
            "Epoch 119/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6726\n",
            "Epoch 120/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6844 \n",
            "Epoch 121/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6143 \n",
            "Epoch 122/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7025 \n",
            "Epoch 123/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5609 \n",
            "Epoch 124/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5775 \n",
            "Epoch 125/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6662 \n",
            "Epoch 126/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6358 \n",
            "Epoch 127/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6504 \n",
            "Epoch 128/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5906 \n",
            "Epoch 129/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6024 \n",
            "Epoch 130/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6384 \n",
            "Epoch 131/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5687 \n",
            "Epoch 132/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6288 \n",
            "Epoch 133/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6363 \n",
            "Epoch 134/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5722 \n",
            "Epoch 135/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6013 \n",
            "Epoch 136/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4941 \n",
            "Epoch 137/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6058 \n",
            "Epoch 138/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5770 \n",
            "Epoch 139/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5882 \n",
            "Epoch 140/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6106 \n",
            "Epoch 141/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6064 \n",
            "Epoch 142/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5358 \n",
            "Epoch 143/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5235 \n",
            "Epoch 144/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5988 \n",
            "Epoch 145/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6332 \n",
            "Epoch 146/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5071 \n",
            "Epoch 147/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5944 \n",
            "Epoch 148/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6143 \n",
            "Epoch 149/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5722 \n",
            "Epoch 150/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5125 \n",
            "Epoch 151/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5348 \n",
            "Epoch 152/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5445 \n",
            "Epoch 153/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6095 \n",
            "Epoch 154/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5864 \n",
            "Epoch 155/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5586 \n",
            "Epoch 156/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5229\n",
            "Epoch 157/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5167 \n",
            "Epoch 158/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5646 \n",
            "Epoch 159/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5241 \n",
            "Epoch 160/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5919 \n",
            "Epoch 161/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6224 \n",
            "Epoch 162/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5016 \n",
            "Epoch 163/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5716 \n",
            "Epoch 164/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5385 \n",
            "Epoch 165/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5616 \n",
            "Epoch 166/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4874 \n",
            "Epoch 167/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5909 \n",
            "Epoch 168/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5176 \n",
            "Epoch 169/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4598 \n",
            "Epoch 170/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5052 \n",
            "Epoch 171/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5382 \n",
            "Epoch 172/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4995 \n",
            "Epoch 173/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5849 \n",
            "Epoch 174/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4913 \n",
            "Epoch 175/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4786 \n",
            "Epoch 176/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4712 \n",
            "Epoch 177/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4970 \n",
            "Epoch 178/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5163 \n",
            "Epoch 179/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5181 \n",
            "Epoch 180/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4431 \n",
            "Epoch 181/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5277 \n",
            "Epoch 182/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5504 \n",
            "Epoch 183/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5286 \n",
            "Epoch 184/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5429 \n",
            "Epoch 185/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5299 \n",
            "Epoch 186/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4831 \n",
            "Epoch 187/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4335 \n",
            "Epoch 188/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4153 \n",
            "Epoch 189/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4987 \n",
            "Epoch 190/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4660\n",
            "Epoch 191/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4634\n",
            "Epoch 192/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5002\n",
            "Epoch 193/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5286\n",
            "Epoch 194/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5261\n",
            "Epoch 195/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5383\n",
            "Epoch 196/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4695 \n",
            "Epoch 197/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5304 \n",
            "Epoch 198/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4583 \n",
            "Epoch 199/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4864\n",
            "Epoch 200/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4122 \n",
            "Epoch 201/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4123 \n",
            "Epoch 202/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4423 \n",
            "Epoch 203/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4595\n",
            "Epoch 204/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4764\n",
            "Epoch 205/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4613\n",
            "Epoch 206/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4469 \n",
            "Epoch 207/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4609\n",
            "Epoch 208/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4407 \n",
            "Epoch 209/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4536\n",
            "Epoch 210/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4512 \n",
            "Epoch 211/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4404 \n",
            "Epoch 212/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4889 \n",
            "Epoch 213/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4215 \n",
            "Epoch 214/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4400 \n",
            "Epoch 215/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4602 \n",
            "Epoch 216/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5050 \n",
            "Epoch 217/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4250 \n",
            "Epoch 218/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4601 \n",
            "Epoch 219/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4645 \n",
            "Epoch 220/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4572 \n",
            "Epoch 221/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4014 \n",
            "Epoch 222/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4607 \n",
            "Epoch 223/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3940 \n",
            "Epoch 224/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4276 \n",
            "Epoch 225/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4716 \n",
            "Epoch 226/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4195 \n",
            "Epoch 227/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4611 \n",
            "Epoch 228/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3966\n",
            "Epoch 229/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4165 \n",
            "Epoch 230/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4698 \n",
            "Epoch 231/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4305 \n",
            "Epoch 232/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4297 \n",
            "Epoch 233/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4830 \n",
            "Epoch 234/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4744 \n",
            "Epoch 235/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4158 \n",
            "Epoch 236/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4216 \n",
            "Epoch 237/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4359 \n",
            "Epoch 238/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4510 \n",
            "Epoch 239/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3707 \n",
            "Epoch 240/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3835 \n",
            "Epoch 241/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4129 \n",
            "Epoch 242/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4007 \n",
            "Epoch 243/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4071 \n",
            "Epoch 244/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4006 \n",
            "Epoch 245/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4277 \n",
            "Epoch 246/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4229 \n",
            "Epoch 247/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4190\n",
            "Epoch 248/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4161  \n",
            "Epoch 249/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4102 \n",
            "Epoch 250/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3987 \n",
            "Epoch 251/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3979 \n",
            "Epoch 252/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4254 \n",
            "Epoch 253/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4057\n",
            "Epoch 254/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4270 \n",
            "Epoch 255/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4198 \n",
            "Epoch 256/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3826 \n",
            "Epoch 257/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4277 \n",
            "Epoch 258/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3913 \n",
            "Epoch 259/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3944 \n",
            "Epoch 260/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3528 \n",
            "Epoch 261/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3692 \n",
            "Epoch 262/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3540 \n",
            "Epoch 263/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3541 \n",
            "Epoch 264/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3458\n",
            "Epoch 265/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3902  \n",
            "Epoch 266/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3951 \n",
            "Epoch 267/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3806 \n",
            "Epoch 268/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3763 \n",
            "Epoch 269/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3569 \n",
            "Epoch 270/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3660 \n",
            "Epoch 271/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3809 \n",
            "Epoch 272/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3788 \n",
            "Epoch 273/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3906 \n",
            "Epoch 274/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3858 \n",
            "Epoch 275/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3804 \n",
            "Epoch 276/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614 \n",
            "Epoch 277/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4062 \n",
            "Epoch 278/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3848 \n",
            "Epoch 279/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3641 \n",
            "Epoch 280/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3556 \n",
            "Epoch 281/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3636\n",
            "Epoch 282/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3693\n",
            "Epoch 283/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3673 \n",
            "Epoch 284/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3349 \n",
            "Epoch 285/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3293 \n",
            "Epoch 286/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4008 \n",
            "Epoch 287/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3364 \n",
            "Epoch 288/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3460 \n",
            "Epoch 289/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3556 \n",
            "Epoch 290/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3541 \n",
            "Epoch 291/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3896 \n",
            "Epoch 292/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3387 \n",
            "Epoch 293/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3556 \n",
            "Epoch 294/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3709 \n",
            "Epoch 295/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3767 \n",
            "Epoch 296/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3379\n",
            "Epoch 297/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3394 \n",
            "Epoch 298/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3421\n",
            "Epoch 299/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3531 \n",
            "Epoch 300/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3766 \n",
            "Epoch 301/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3171 \n",
            "Epoch 302/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3438 \n",
            "Epoch 303/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3669 \n",
            "Epoch 304/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3580 \n",
            "Epoch 305/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3394 \n",
            "Epoch 306/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3756\n",
            "Epoch 307/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3500 \n",
            "Epoch 308/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3269\n",
            "Epoch 309/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3295 \n",
            "Epoch 310/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3111 \n",
            "Epoch 311/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3732 \n",
            "Epoch 312/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3715 \n",
            "Epoch 313/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3317 \n",
            "Epoch 314/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3001 \n",
            "Epoch 315/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3348 \n",
            "Epoch 316/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3595  \n",
            "Epoch 317/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3386 \n",
            "Epoch 318/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3196 \n",
            "Epoch 319/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3570 \n",
            "Epoch 320/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3306 \n",
            "Epoch 321/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2961 \n",
            "Epoch 322/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3107 \n",
            "Epoch 323/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3242 \n",
            "Epoch 324/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3190 \n",
            "Epoch 325/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3381 \n",
            "Epoch 326/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3683 \n",
            "Epoch 327/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3090 \n",
            "Epoch 328/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3325 \n",
            "Epoch 329/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3095 \n",
            "Epoch 330/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2761 \n",
            "Epoch 331/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3214\n",
            "Epoch 332/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3126\n",
            "Epoch 333/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3478 \n",
            "Epoch 334/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3185 \n",
            "Epoch 335/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3543\n",
            "Epoch 336/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2988 \n",
            "Epoch 337/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3099 \n",
            "Epoch 338/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2796 \n",
            "Epoch 339/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3186\n",
            "Epoch 340/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3278 \n",
            "Epoch 341/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2704 \n",
            "Epoch 342/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3169 \n",
            "Epoch 343/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2779 \n",
            "Epoch 344/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3485 \n",
            "Epoch 345/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3044 \n",
            "Epoch 346/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3042 \n",
            "Epoch 347/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3045 \n",
            "Epoch 348/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2982 \n",
            "Epoch 349/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3109\n",
            "Epoch 350/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3304 \n",
            "Epoch 351/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3193 \n",
            "Epoch 352/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2989\n",
            "Epoch 353/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2932 \n",
            "Epoch 354/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2898\n",
            "Epoch 355/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2876 \n",
            "Epoch 356/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2738 \n",
            "Epoch 357/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3187 \n",
            "Epoch 358/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2863 \n",
            "Epoch 359/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3166 \n",
            "Epoch 360/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3116 \n",
            "Epoch 361/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2772 \n",
            "Epoch 362/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2990 \n",
            "Epoch 363/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2887 \n",
            "Epoch 364/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3196 \n",
            "Epoch 365/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2454 \n",
            "Epoch 366/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2636 \n",
            "Epoch 367/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2752\n",
            "Epoch 368/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2972\n",
            "Epoch 369/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2511 \n",
            "Epoch 370/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2646 \n",
            "Epoch 371/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2780\n",
            "Epoch 372/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2772 \n",
            "Epoch 373/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2930\n",
            "Epoch 374/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3246 \n",
            "Epoch 375/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2655 \n",
            "Epoch 376/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2929 \n",
            "Epoch 377/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3173\n",
            "Epoch 378/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2986\n",
            "Epoch 379/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2877\n",
            "Epoch 380/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2588\n",
            "Epoch 381/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2827\n",
            "Epoch 382/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2527\n",
            "Epoch 383/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3007\n",
            "Epoch 384/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2591 \n",
            "Epoch 385/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2571 \n",
            "Epoch 386/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2553\n",
            "Epoch 387/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2528 \n",
            "Epoch 388/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2537\n",
            "Epoch 389/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2562 \n",
            "Epoch 390/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2845 \n",
            "Epoch 391/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2778 \n",
            "Epoch 392/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2396\n",
            "Epoch 393/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2809 \n",
            "Epoch 394/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2738\n",
            "Epoch 395/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2304\n",
            "Epoch 396/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2203 \n",
            "Epoch 397/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2301\n",
            "Epoch 398/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2761\n",
            "Epoch 399/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2793\n",
            "Epoch 400/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a13e4c91bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    keras.Input(shape=(1,)),\n",
        "    #Seu código aqui\n",
        "    keras.layers.Dense(units=10, activation='tanh'),\n",
        "    keras.layers.Dense(units=1)\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"RMSprop\", loss=\"mean_squared_error\")\n",
        "model.fit(x,y,epochs=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "YXemXqt4JxSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "536cdf40-85da-4914-ef1f-ba20293725ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m20\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64\u001b[0m (260.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (260.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31\u001b[0m (124.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (124.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m33\u001b[0m (136.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (136.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "CDe4v2urJxSw"
      },
      "outputs": [],
      "source": [
        "x_val = np.linspace(0,10,63)\n",
        "y_val = f2(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "En-fuX_pJxSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d7da0c-64a6-45b5-d1be-82c702d57d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26000267267227173"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "model.evaluate(x=x_val,y=y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN1TP49KJxSw"
      },
      "source": [
        "____________________________\n",
        "# <font color='blue'>Questão 2 </font>\n",
        "\n",
        "\n",
        "\n",
        "O que acontece se você muda as funções de ativação? Teste algumas diferentes e descreva seus resultados, em especial a tangente hiperbólica\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEUr4h63JxSx"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>** Ao adicionar uma camada oculta com função de ativação não-linear (tanh), a rede aumentou significativamente sua capacidade de aprender a função f2(x) = (x² + x³)/200. Apesar do número de parâmetros aumentar (de 8 para 95), o modelo obteve uma loss final menor e um desempenho melhor na avaliação. A função de ativação tanh, por ser simétrica e permitir valores negativos e positivos, ajudou a rede a capturar a forma da função-alvo com mais precisão. Isso mostra a importância de funções de ativação nas camadas intermediárias para aprender padrões não-lineares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkfBe5PPJxSx"
      },
      "source": [
        "\n",
        "O que acontece se você mudar a função de otimização? Teste diferentes funções e descreva seus resultados, em especial as funções SDG e RMSprop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqpZdJsAJxSx"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>** Testei diferentes otimizadores para a função f2(x) = (x² + x³)/200.\n",
        "O SGD apresentou uma loss inicial alta (9.3198) e convergiu para uma loss de avaliação de 0.1798. Embora tenha poucos parâmetros (33), ele convergiu de forma mais lenta e com mais oscilação.\n",
        "Já o RMSprop, que ajusta o passo de aprendizagem dinamicamente, teve loss final menor (0.1513), indicando que aprendeu a função com mais precisão. O modelo com RMSprop também usou mais parâmetros (64), o que pode ter contribuído para sua capacidade de aprender padrões mais complexos.\n",
        "No geral, RMSprop se saiu melhor que SGD, especialmente para essa tarefa com função não-linear.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW_UYiHBJxSx"
      },
      "source": [
        "Volte a primeira parte desse notebook e troque a função de ativação da rede de uma camada (pérceptron) de sdg para adam, o que acontece?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8O4EZlJxSx"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>** Neste teste com uma rede de uma camada (perceptron) para aprender a função linear f(x) = 5 + 10x, o otimizador SGD teve desempenho significativamente melhor do que Adam. Enquanto o SGD convergiu rapidamente para um valor de perda próximo de zero e gerou uma predição quase exata, o Adam permaneceu com uma perda muito alta. Isso mostra que, em funções simples e lineares, otimizadores mais sofisticados como o Adam podem não trazer vantagem e até dificultar a convergência. Já o SGD, com seu comportamento direto, é mais adequado para esse tipo de tarefa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWPZ5SbwJxSy"
      },
      "source": [
        "A avaliação de performance que realizamos foi apenas para pontos contidos no mesmo intervalo que o conjunto de treino, ou seja, foi apenas uma interpolação. Sem alterar sua rede repita o teste realizando uma extrapolação, com pontos fora do intervalo [0;10] e descreva seus resultados. O que aconteceu com a performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "JWHLgtqxJxSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2516d939-4a50-4718-b360-e25a44209ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0467e-04 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001824299688450992"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "x_val_extrapolado = np.linspace(-10, 20, 100)\n",
        "y_val_extrapolado = f1(x_val_extrapolado)\n",
        "model.evaluate(x=x_val_extrapolado,y=y_val_extrapolado)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU86EmBmJxSy"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**Durante a avaliação do modelo, notei que a performance dentro do intervalo de treino ([0,10]) resultou em um loss de aproximadamente 2.59e-05, enquanto fora do intervalo ([-10, 20]) o loss foi de 2.04e-04.\n",
        "\n",
        "Isso confirma que o modelo tem pior desempenho na extrapolação, como esperado, mesmo que a diferença de erro não tenha sido muito drástica. Isso provavelmente se deve ao fato de que a função aprendida era linear, o que facilita a generalização fora do intervalo.\n",
        "\n",
        "O aumento da quantidade de pontos (de 63 para 100) no linspace pode ter ajudado a suavizar a média da função de perda, mas não é a principal razão da diferença observada. O comportamento é coerente com o esperado para uma regressão linear simples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYIHWLNKJxSz"
      },
      "source": [
        "# Prevendo se vai chover na Austrália\n",
        "\n",
        "Os próximos exercícios são, em grande parte, uma tradução e adaptação para o português brasileiro do tutorial intitulado [Build Your First Neural Network with Pytorch](https://curiousily.com/posts/build-your-first-neural-network-with-pytorch/)\n",
        " entretanto algumas adaptações foram realizadas, tanto no texto, quanto no código, em relação à versão original para utilizar a biblioteca TensorFlow.\n",
        "\n",
        "Aqui você aprenderá como implementar, treinar e utilizar uma Rede Neural *Feed-Foward* simples para uma tarefa de classificação binária.\n",
        "\n",
        "Para tal, utilizaremos o pacote [TensorFlow 2.0](www.tensorflow.org) que é, atualmente, uma das principais ferramentas para a implementação de modelos neurais viáveis.\n",
        "\n",
        "A tarefa que usaremos para fins de exemplo será a de prever se choverá ou não numa cidade australiana amanhã, utilizando dados meteorológicos mensurados na mesma cidade no dia de hoje. A redução dessa tarefa de previsão a uma classificação binária é, evidentemente, uma grande simplificação do problema real de previsão meteorológica, mas como veremos, ainda pode apresentar resultados interessantes, além do caráter didático.\n",
        "\n",
        "\n",
        "\n",
        "As informações que utilizaremos para treinar nosso modelo para a tarefa de previsão de chuvas estão contidas num conjunto que reúne dados meteorológicos de diversas cidades australianas. Esse conjunto de dados foi curado e disponibilizado através do [Kaggle](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) por [Joe Young](https://www.kaggle.com/jsphyg).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "LcJL3ba5WnDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando os dados:\n",
        "!curl https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/Semana%2002/data/weatherAUS.csv --output 'data/weatherAUS.csv'"
      ],
      "metadata": {
        "id": "SpUaQLuKXGJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados estão no formato `.csv` e, com eles em mãos, o primeiro passo é carregá-los em um *data-frame*, usando a função [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) do *pandas*.\n",
        "\n",
        "\n",
        "Com os dados carregados, é possível averiguar que eles são constituídos por 142193 entradas, cada uma contando com 24 variáveis distintas. É possível notar, também, que existem entradas para as quais nem todas as variáveis estão  instanciadas. Além disso, nem todos os valores estão nos formatos que gostaríamos que estivessem para serem processados.\n",
        "\n",
        "Isso é normal. Dados reais são cheios de falhas e problemas, e exigem trabalho e entendimento para serem utilizados da maneira correta. Por isso, é necessário realizar um **pré-processamento** para adequar os dados, antes de os passarmos para o modelo.\n",
        "\n",
        "O primeiro passo é escolher quais das variáveis meteorológicas nos interessam. No nosso caso, queremos prever se choverá ou não amanhã, então `RainTomorrow` será nossa variável alvo. Para prevê-la usaremos as variáveis  `Rainfall`, `Humidity3pm`, `Pressure9am` e `RainToday`, que serão nossas *features*.\n",
        "\n",
        "\n",
        "\n",
        "Em seguida, iniciamos o pré-processamento, propriamente dito.\n",
        "\n",
        "As variáveis `RainToday` e `RainTomorrow` possuem dois valores possíveis, *Yes* e *No*. Adeque esses valores, convertendo-os para $1$ e $0$, respectivamente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A seguir, remova todas as entradas que não tenham instanciado os valores de todas as variáveis de interesse com a função [`dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), pois essas entradas são inúteis para treinar nosso modelo.\n",
        "\n",
        "\n",
        "\n",
        "Com os dados pré-processados, é possível, agora, plotar as distribuições das variáveis de interesse para poder entender melhor como essas distribuições funcionam. Esse tipo de trabalho é muito importante na implementação real de redes neurais, conhecer os dados é fundamental para tirar o maior proveito do seu modelo e entender verdadeiramente seus resultados.\n",
        "\n"
      ],
      "metadata": {
        "id": "XiS7Hc97Tn9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "awiT8tbUQmER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dentre todas as distribuições das variáveis de interesse, a que mais nos concerne é a da variável alvo, `RainTomorrow`, representada na figura acima.\n",
        "\n",
        "\n",
        "Essa distribuição nos revela um grande desbalanço entre os dois valores possíveis dessa variável, que constituirão as duas classes do nosso problema de classificação. Esse é um dado importante, pois pode influenciar significativamente a capacidade preditiva do modelo treinado.\n",
        "\n",
        "Existem maneiras de se lidar com o desbalanceamento dos dados, mas nesse tutorial utilizaremos os dados dessa forma. Isso significa que o *baseline* para a performance do nosso modelo deve ser $78\\%$, isso porque, se um modelo chutasse que amanhã não irá chover, todas as vezes, ele obteria uma performance dessa ordem e, como esperamos gerar um modelo mais \"inteligente\" que isso, esperamos também que a a nossa performance seja superior a essa.\n",
        "\n",
        "Todo o código referente a esse pré-processamento deve ser escrito pelo próprio aluno seguindo o esqueleto das funções presentes no notebook. Para agilizar a exploração dos dados nós já fornecemos a implementação da função `visualize_data()` que plota visualizações para as distribuições das variáveis de interesse."
      ],
      "metadata": {
        "id": "cay4UNFYTjZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZEbIjnPJxSz"
      },
      "outputs": [],
      "source": [
        "def visualize_data(data):\n",
        "    \"\"\"Gera graficos das distribuicoes das features\"\"\"\n",
        "\n",
        "    ibm_pltt = ['#648FFF', '#785EF0', '#DC267F',\n",
        "                '#FE6100', '#FFB000']  # Paleta colorblind-friendly\n",
        "\n",
        "    # RainToday:\n",
        "    sns.set()\n",
        "    sns.set_palette(sns.color_palette([ibm_pltt[2], ibm_pltt[0]]))\n",
        "    sns.countplot(x=data.RainToday)\n",
        "    plt.xlabel('Choveu Hoje?')\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.title(\"Valores de 'RainToday' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # RainTomorrow:\n",
        "    sns.set()\n",
        "    sns.set_palette(sns.color_palette([ibm_pltt[3], ibm_pltt[1]]))\n",
        "    sns.countplot(x=data.RainTomorrow)\n",
        "    plt.xlabel('Choverá Amanhã?')\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.title(\"Valores de 'RainTomorrow' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Humidity3pm:\n",
        "    sns.set()\n",
        "    sns.displot(data.Humidity3pm, color=ibm_pltt[0], stat='density', kde=True)\n",
        "    plt.xlabel('Umidade às 3PM')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Humidity3pm' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Pressure9am:\n",
        "    sns.set()\n",
        "    sns.displot(data.Pressure9am, color=ibm_pltt[4], stat='density', kde=True)\n",
        "    plt.xlabel('Pressão atmosférica às 9AM')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Pressure9amm' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Rainfall:\n",
        "    sns.set()\n",
        "    sns.histplot(data.Rainfall, color=ibm_pltt[1], bins=500, kde=False)\n",
        "    plt.xlim(0, 10)\n",
        "    plt.xlabel('Pluviosidade')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Rainfall' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O_WugijJxSz"
      },
      "source": [
        "## Pré processamento dos dados\n",
        "Já definimos uma função basica para lhe ajudar a explorar os dados, você precisará escrever uma função para carregar os dados, uma de pré-processamento e outra para fazer a separação em teste e treino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk6JHolSJxSz"
      },
      "source": [
        "# <font color='blue'>Questão 3 </font>\n",
        "Complete as funções aqui descritas seguindo a assinatura sugerida\n",
        "\n",
        "Para separar em treino e teste, de uma olhada na função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI5ggHUlJxS0"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path='data/weatherAUS.csv')-> pd.DataFrame:\n",
        "    \"\"\"Funcao que importa dados de um arquivo csv, usando pandas\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return raw_data\n",
        "\n",
        "def pre_processing(raw_data:pd.DataFrame)-> pd.DataFrame:\n",
        "    \"\"\"Funcao que filtra e limpa os dados meteorologicos para o treinamento\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "def split_data(data:pd.DataFrame, val_size= 0.2)-> np.array:\n",
        "    \"\"\"Funcao que separa seus dados em teste e treino conforme a proporcao val_size\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return x_train, x_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytKb1DlsJxS0"
      },
      "outputs": [],
      "source": [
        "df = load_data()\n",
        "df = pre_processing(df)\n",
        "visualize_data(df)\n",
        "x_train, x_val, y_train, y_val = split_data(df,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F0iWfJYJxS0"
      },
      "source": [
        "# <font color='blue'>Questão 4 </font>\n",
        "Agora que você ja ganhou uma familiaridade com a API Keras, escreva sozinho do começo ao fim um modelo que ira dizer se amanhã vai chover ou não e avalie sua performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loD7lw_tJxS1"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_tutorial",
      "language": "python",
      "name": ".venv_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of 02 - NN & Backpropagation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}